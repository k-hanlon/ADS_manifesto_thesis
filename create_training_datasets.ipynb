{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the MP q_sentence data and the party split info\n",
    "corpus_df = pd.read_csv(\"data/english_annotated_full_df.csv\") # full df or reduced df?\n",
    "split_df = pd.read_csv(\"data/party_split.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the index of the corpus_df and save it as a column. This way we can always find and compare q_sentences later on\n",
    "corpus_df = corpus_df.reset_index(names=\"original_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some q_sentences are very long (and don't follow the rules of max. 1 sentence)\n",
    "# this will be a problem for the max token input of roBERTa of 512 (esp. for the context model)\n",
    "# we we will remove all q_sentences that have 100 or more words\n",
    "#  these are 96 q_sentences in total, so not very many\n",
    "corpus_df = corpus_df[corpus_df[\"q_sentence_words\"] < 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_index</th>\n",
       "      <th>q_sentence</th>\n",
       "      <th>q_sentence_nr</th>\n",
       "      <th>codes</th>\n",
       "      <th>manifesto_id</th>\n",
       "      <th>party</th>\n",
       "      <th>date</th>\n",
       "      <th>language</th>\n",
       "      <th>handbook</th>\n",
       "      <th>title</th>\n",
       "      <th>coderid</th>\n",
       "      <th>countryname</th>\n",
       "      <th>partyname</th>\n",
       "      <th>pervote</th>\n",
       "      <th>q_sentence_chars</th>\n",
       "      <th>q_sentence_words</th>\n",
       "      <th>main_codes</th>\n",
       "      <th>RILE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Which party will make a real difference to my ...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51421_199705</td>\n",
       "      <td>51421</td>\n",
       "      <td>199705</td>\n",
       "      <td>english</td>\n",
       "      <td>1</td>\n",
       "      <td>Make the Difference</td>\n",
       "      <td>102</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Liberal Democrats</td>\n",
       "      <td>16.758</td>\n",
       "      <td>64</td>\n",
       "      <td>11</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Our aim: To make Britain the world's foremost ...</td>\n",
       "      <td>2</td>\n",
       "      <td>411</td>\n",
       "      <td>51421_199705</td>\n",
       "      <td>51421</td>\n",
       "      <td>199705</td>\n",
       "      <td>english</td>\n",
       "      <td>1</td>\n",
       "      <td>Make the Difference</td>\n",
       "      <td>102</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Liberal Democrats</td>\n",
       "      <td>16.758</td>\n",
       "      <td>71</td>\n",
       "      <td>12</td>\n",
       "      <td>411</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original_index                                         q_sentence  \\\n",
       "0               0  Which party will make a real difference to my ...   \n",
       "1               1  Our aim: To make Britain the world's foremost ...   \n",
       "\n",
       "   q_sentence_nr codes  manifesto_id  party    date language  handbook  \\\n",
       "0              1   NaN  51421_199705  51421  199705  english         1   \n",
       "1              2   411  51421_199705  51421  199705  english         1   \n",
       "\n",
       "                 title  coderid     countryname          partyname  pervote  \\\n",
       "0  Make the Difference      102  United Kingdom  Liberal Democrats   16.758   \n",
       "1  Make the Difference      102  United Kingdom  Liberal Democrats   16.758   \n",
       "\n",
       "   q_sentence_chars  q_sentence_words  main_codes  RILE  \n",
       "0                64                11          -1     0  \n",
       "1                71                12         411     0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>manifesto_id</th>\n",
       "      <th>year</th>\n",
       "      <th>countryname</th>\n",
       "      <th>partyname</th>\n",
       "      <th>migration_positive</th>\n",
       "      <th>left_right</th>\n",
       "      <th>green</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51421_199705</td>\n",
       "      <td>1997</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Liberal Democrats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Center</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51902_199705</td>\n",
       "      <td>1997</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Scottish National Party</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Left</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   manifesto_id  year     countryname                partyname  \\\n",
       "0  51421_199705  1997  United Kingdom        Liberal Democrats   \n",
       "1  51902_199705  1997  United Kingdom  Scottish National Party   \n",
       "\n",
       "   migration_positive left_right green  \n",
       "0                 NaN     Center    No  \n",
       "1                 NaN       Left    No  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(209, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "left_right\n",
       "Left            80\n",
       "Right           64\n",
       "Center          22\n",
       "Center-right    22\n",
       "Center-left     15\n",
       "NaN              4\n",
       "Far-left         2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_df[\"left_right\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "green\n",
       "No     189\n",
       "Yes     20\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_df[\"green\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NAs in left_right with \"Unknown\"\n",
    "split_df['left_right'] = split_df['left_right'].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recode the columns\n",
    "# TODO: FIX THIS FOR Left vs. center+right and right vs. center+left\n",
    "# LEFT = 1, CENTER = 0, RIGHT = 2, Unknown = -1 --> similar to RILE coding in the corpus_dfs\n",
    "left_right_dict = {\"Far-left\": 1,\n",
    "                   \"Left\": 1,\n",
    "                   \"Center-left\": 1,\n",
    "                   \"Center\": 0,\n",
    "                   \"Center-right\": 2,\n",
    "                   \"Right\": 2,\n",
    "                   \"Unknown\": -1}\n",
    "split_df = split_df.assign(left_right  = split_df.left_right.map(left_right_dict))\n",
    "\n",
    "# Green = 1\n",
    "green_dict = {\"Yes\": 1,\n",
    "              \"No\": 0}\n",
    "split_df = split_df.assign(green  = split_df.green.map(green_dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>manifesto_id</th>\n",
       "      <th>year</th>\n",
       "      <th>countryname</th>\n",
       "      <th>partyname</th>\n",
       "      <th>migration_positive</th>\n",
       "      <th>left_right</th>\n",
       "      <th>green</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51421_199705</td>\n",
       "      <td>1997</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Liberal Democrats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51902_199705</td>\n",
       "      <td>1997</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Scottish National Party</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   manifesto_id  year     countryname                partyname  \\\n",
       "0  51421_199705  1997  United Kingdom        Liberal Democrats   \n",
       "1  51902_199705  1997  United Kingdom  Scottish National Party   \n",
       "\n",
       "   migration_positive  left_right  green  \n",
       "0                 NaN           0      0  \n",
       "1                 NaN           1      0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "left_right\n",
       " 1    97\n",
       " 2    86\n",
       " 0    22\n",
       "-1     4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_df[\"left_right\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge left_right to the corpus_df:\n",
    "corpus_df = corpus_df.merge(split_df, on=\"manifesto_id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a binary label column for green codes (so code 501 is 1, rest is 0)\n",
    "corpus_df[\"green_code\"] = [1 if x == 501 else 0 for x in corpus_df[\"main_codes\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_index</th>\n",
       "      <th>q_sentence</th>\n",
       "      <th>q_sentence_nr</th>\n",
       "      <th>codes</th>\n",
       "      <th>manifesto_id</th>\n",
       "      <th>party</th>\n",
       "      <th>date</th>\n",
       "      <th>language</th>\n",
       "      <th>handbook</th>\n",
       "      <th>title</th>\n",
       "      <th>coderid</th>\n",
       "      <th>countryname_x</th>\n",
       "      <th>partyname_x</th>\n",
       "      <th>pervote</th>\n",
       "      <th>q_sentence_chars</th>\n",
       "      <th>q_sentence_words</th>\n",
       "      <th>main_codes</th>\n",
       "      <th>RILE</th>\n",
       "      <th>year</th>\n",
       "      <th>countryname_y</th>\n",
       "      <th>partyname_y</th>\n",
       "      <th>migration_positive</th>\n",
       "      <th>left_right</th>\n",
       "      <th>green</th>\n",
       "      <th>green_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Which party will make a real difference to my ...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51421_199705</td>\n",
       "      <td>51421</td>\n",
       "      <td>199705</td>\n",
       "      <td>english</td>\n",
       "      <td>1</td>\n",
       "      <td>Make the Difference</td>\n",
       "      <td>102</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Liberal Democrats</td>\n",
       "      <td>16.758</td>\n",
       "      <td>64</td>\n",
       "      <td>11</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1997</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Liberal Democrats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Our aim: To make Britain the world's foremost ...</td>\n",
       "      <td>2</td>\n",
       "      <td>411</td>\n",
       "      <td>51421_199705</td>\n",
       "      <td>51421</td>\n",
       "      <td>199705</td>\n",
       "      <td>english</td>\n",
       "      <td>1</td>\n",
       "      <td>Make the Difference</td>\n",
       "      <td>102</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Liberal Democrats</td>\n",
       "      <td>16.758</td>\n",
       "      <td>71</td>\n",
       "      <td>12</td>\n",
       "      <td>411</td>\n",
       "      <td>0</td>\n",
       "      <td>1997</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Liberal Democrats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   original_index                                         q_sentence  \\\n",
       "0               0  Which party will make a real difference to my ...   \n",
       "1               1  Our aim: To make Britain the world's foremost ...   \n",
       "\n",
       "   q_sentence_nr codes  manifesto_id  party    date language  handbook  \\\n",
       "0              1   NaN  51421_199705  51421  199705  english         1   \n",
       "1              2   411  51421_199705  51421  199705  english         1   \n",
       "\n",
       "                 title  coderid   countryname_x        partyname_x  pervote  \\\n",
       "0  Make the Difference      102  United Kingdom  Liberal Democrats   16.758   \n",
       "1  Make the Difference      102  United Kingdom  Liberal Democrats   16.758   \n",
       "\n",
       "   q_sentence_chars  q_sentence_words  main_codes  RILE  year   countryname_y  \\\n",
       "0                64                11          -1     0  1997  United Kingdom   \n",
       "1                71                12         411     0  1997  United Kingdom   \n",
       "\n",
       "         partyname_y  migration_positive  left_right  green  green_code  \n",
       "0  Liberal Democrats                 NaN           0      0           0  \n",
       "1  Liberal Democrats                 NaN           0      0           0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Green Party of England and Wales', 'Green Party',\n",
       "       'Australian Greens', 'Green Party of Aotearoa New Zealand'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all green parties:\n",
    "corpus_df[corpus_df[\"green\"] == 1][\"partyname_x\"].unique() # careful, two different parties are named \"Green Party\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Left-Right Split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this removes the 4 \"unknown\" parties\n",
    "left_df = corpus_df[corpus_df[\"left_right\"] == 1]\n",
    "right_df = corpus_df[corpus_df[\"left_right\"] == 2]\n",
    "center_df = corpus_df[corpus_df[\"left_right\"] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are top frequent codes for the different sets? How many R/L/N are there in RILE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main_codes\n",
       " 504    0.111608\n",
       " 501    0.072527\n",
       "-1      0.068304\n",
       " 503    0.065650\n",
       " 411    0.064311\n",
       " 0      0.061849\n",
       " 506    0.053367\n",
       " 701    0.038924\n",
       " 416    0.031673\n",
       " 403    0.031250\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(left_df[\"main_codes\"].value_counts()/(left_df.shape[0]))[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RILE\n",
       "0    0.556486\n",
       "1    0.314989\n",
       "2    0.128525\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_df[\"RILE\"].value_counts()/left_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main_codes\n",
       " 504    0.084268\n",
       " 411    0.071210\n",
       "-1      0.063574\n",
       " 0      0.059953\n",
       " 605    0.057040\n",
       " 703    0.044648\n",
       " 506    0.043296\n",
       " 503    0.040863\n",
       " 410    0.038060\n",
       " 402    0.035343\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(right_df[\"main_codes\"].value_counts()/(right_df.shape[0]))[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RILE\n",
       "0    0.494655\n",
       "2    0.275035\n",
       "1    0.230310\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right_df[\"RILE\"].value_counts()/right_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "main_codes\n",
       " 504    0.116494\n",
       "-1      0.095947\n",
       " 411    0.060057\n",
       " 506    0.051687\n",
       " 0      0.050028\n",
       " 501    0.049840\n",
       " 605    0.043129\n",
       " 503    0.040226\n",
       " 303    0.037210\n",
       " 301    0.033893\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(center_df[\"main_codes\"].value_counts()/(center_df.shape[0]))[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RILE\n",
       "0    0.551593\n",
       "1    0.275137\n",
       "2    0.173270\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "center_df[\"RILE\"].value_counts()/center_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what columns do we need in the data for the model?\n",
    "relevant_cols = [\"q_sentence\", \"q_sentence_nr\", \"manifesto_id\", \"main_codes\", \"RILE\", \"original_index\"]\n",
    "left_df = left_df[relevant_cols]\n",
    "right_df = right_df[relevant_cols]\n",
    "center_df = center_df[relevant_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of q_sentences in the training set: 58067\n",
      "Number of q_sentences in the validation set: 12284\n",
      "Number of q_sentences in the test set: 12528\n",
      "Percentage of the train set: 0.7006238009628495\n",
      "Percentage of the validation set: 0.14821607403564233\n",
      "Percentage of the test set: 0.15116012500150822\n"
     ]
    }
   ],
   "source": [
    "# left as train\n",
    "# train: 70% Left\n",
    "# validation: 15% Left\n",
    "# test: 15% Left\n",
    "# inference_right: 100% Right\n",
    "# inference_center: 100% Center\n",
    "\n",
    "# split on manifestos:\n",
    "manifesto_ids = left_df[\"manifesto_id\"].unique()\n",
    "np.random.seed(6) # keep it reproducible (and so that ca. 10% of the q_sentences land in the validation set)\n",
    "np.random.shuffle(manifesto_ids)\n",
    "\n",
    "# select manifestos into the different sets (so that about 15% of q_sentences are in the validation and test sets, see below)\n",
    "train_manifesto_ids = manifesto_ids[28:] # 10 manifestos\n",
    "val_manifesto_ids = manifesto_ids[:13] # 13\n",
    "test_manifesto_ids = manifesto_ids[13:28] # 7 manifestos\n",
    "\n",
    "train_df = left_df[left_df[\"manifesto_id\"].isin(train_manifesto_ids)]\n",
    "val_df = left_df[left_df[\"manifesto_id\"].isin(val_manifesto_ids)]\n",
    "test_df = left_df[left_df[\"manifesto_id\"].isin(test_manifesto_ids)]\n",
    "inference_right_df = right_df.copy()\n",
    "inference_center_df = center_df.copy()\n",
    "\n",
    "print(\"Number of q_sentences in the training set:\", train_df.shape[0])\n",
    "print(\"Number of q_sentences in the validation set:\", val_df.shape[0])\n",
    "print(\"Number of q_sentences in the test set:\", test_df.shape[0])\n",
    "print(\"Percentage of the train set:\", train_df.shape[0]/left_df.shape[0])\n",
    "print(\"Percentage of the validation set:\", val_df.shape[0]/left_df.shape[0])\n",
    "print(\"Percentage of the test set:\", test_df.shape[0]/left_df.shape[0])\n",
    "\n",
    "# make sure they are sorted correctly (important for adding the context later on)\n",
    "train_df = train_df.sort_values([\"manifesto_id\", \"q_sentence_nr\"], ascending=True)\n",
    "val_df = val_df.sort_values([\"manifesto_id\", \"q_sentence_nr\"], ascending=True)\n",
    "test_df = test_df.sort_values([\"manifesto_id\", \"q_sentence_nr\"], ascending=True)\n",
    "inference_right_df = inference_right_df.sort_values([\"manifesto_id\", \"q_sentence_nr\"], ascending=True)\n",
    "inference_center_df = inference_center_df.sort_values([\"manifesto_id\", \"q_sentence_nr\"], ascending=True)\n",
    "\n",
    "# and reset the indicies\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "val_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "inference_right_df.reset_index(drop=True, inplace=True)\n",
    "inference_center_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# and now save them as csv so that they can be loaded into huggingface\n",
    "# train_df.to_csv(\"data/model_splits/left_right_split/left_as_train/train-00000-of-00001.csv\", index=False)\n",
    "# val_df.to_csv(\"data/model_splits/left_right_split/left_as_train/validation-00000-of-00001.csv\", index=False)\n",
    "# test_df.to_csv(\"data/model_splits/left_right_split/left_as_train/test-00000-of-00001.csv\", index=False)\n",
    "# inference_right_df.to_csv(\"data/model_splits/left_right_split/left_as_train/inference_right-00000-of-00001.csv\", index=False)\n",
    "# inference_center_df.to_csv(\"data/model_splits/left_right_split/left_as_train/inference_center-00000-of-00001.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(manifesto_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RILE proportions in train:\n",
      " RILE\n",
      "0    0.545404\n",
      "1    0.322524\n",
      "2    0.132072\n",
      "Name: count, dtype: float64\n",
      "\n",
      "RILE proportions in validation:\n",
      " RILE\n",
      "0    0.581895\n",
      "1    0.291192\n",
      "2    0.126913\n",
      "Name: count, dtype: float64\n",
      "\n",
      "RILE proportions in test:\n",
      " RILE\n",
      "0    0.582934\n",
      "1    0.303400\n",
      "2    0.113665\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"RILE proportions in train:\\n\", train_df[\"RILE\"].value_counts()/train_df.shape[0])\n",
    "print(\"\\nRILE proportions in validation:\\n\", val_df[\"RILE\"].value_counts()/val_df.shape[0])\n",
    "print(\"\\nRILE proportions in test:\\n\", test_df[\"RILE\"].value_counts()/test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RILE proportions in inference right:\n",
      " RILE\n",
      "0    0.494655\n",
      "2    0.275035\n",
      "1    0.230310\n",
      "Name: count, dtype: float64\n",
      "\n",
      "RILE proportions in inference center:\n",
      " RILE\n",
      "0    0.551593\n",
      "1    0.275137\n",
      "2    0.173270\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRILE proportions in inference right:\\n\", inference_right_df[\"RILE\"].value_counts()/inference_right_df.shape[0])\n",
    "print(\"\\nRILE proportions in inference center:\\n\", inference_center_df[\"RILE\"].value_counts()/inference_center_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of q_sentences in the training set: 64260\n",
      "Number of q_sentences in the validation set: 13335\n",
      "Number of q_sentences in the test set: 14077\n",
      "Percentage of the train set: 0.7009773976786805\n",
      "Percentage of the validation set: 0.14546426389737324\n",
      "Percentage of the test set: 0.15355833842394626\n"
     ]
    }
   ],
   "source": [
    "# right as train\n",
    "# train: 70% right\n",
    "# validation: 15% right\n",
    "# test: 15% right\n",
    "# inference_left: 100% Left\n",
    "# inference_center: 100% Center\n",
    "\n",
    "# split on manifestos:\n",
    "manifesto_ids = right_df[\"manifesto_id\"].unique()\n",
    "np.random.seed(19) # keep it reproducible (and so that ca. 10% of the q_sentences land in the validation set)\n",
    "np.random.shuffle(manifesto_ids)\n",
    "\n",
    "# select manifestos into the different sets (so that about 15% of q_sentences are in the validation and test sets, see below)\n",
    "train_manifesto_ids = manifesto_ids[26:] #\n",
    "val_manifesto_ids = manifesto_ids[:13] #\n",
    "test_manifesto_ids = manifesto_ids[13:26] #\n",
    "\n",
    "train_df = right_df[right_df[\"manifesto_id\"].isin(train_manifesto_ids)]\n",
    "val_df = right_df[right_df[\"manifesto_id\"].isin(val_manifesto_ids)]\n",
    "test_df = right_df[right_df[\"manifesto_id\"].isin(test_manifesto_ids)]\n",
    "inference_left_df = left_df.copy()\n",
    "inference_center_df = center_df.copy()\n",
    "\n",
    "print(\"Number of q_sentences in the training set:\", train_df.shape[0])\n",
    "print(\"Number of q_sentences in the validation set:\", val_df.shape[0])\n",
    "print(\"Number of q_sentences in the test set:\", test_df.shape[0])\n",
    "print(\"Percentage of the train set:\", train_df.shape[0]/right_df.shape[0])\n",
    "print(\"Percentage of the validation set:\", val_df.shape[0]/right_df.shape[0])\n",
    "print(\"Percentage of the test set:\", test_df.shape[0]/right_df.shape[0])\n",
    "\n",
    "# make sure they are sorted correctly (important for adding the context later on)\n",
    "train_df = train_df.sort_values([\"manifesto_id\", \"q_sentence_nr\"], ascending=True)\n",
    "val_df = val_df.sort_values([\"manifesto_id\", \"q_sentence_nr\"], ascending=True)\n",
    "test_df = test_df.sort_values([\"manifesto_id\", \"q_sentence_nr\"], ascending=True)\n",
    "inference_left_df = inference_left_df.sort_values([\"manifesto_id\", \"q_sentence_nr\"], ascending=True)\n",
    "inference_center_df = inference_center_df.sort_values([\"manifesto_id\", \"q_sentence_nr\"], ascending=True)\n",
    "\n",
    "# and reset the indicies\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "val_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "inference_left_df.reset_index(drop=True, inplace=True)\n",
    "inference_center_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# and now save them as csv so that they can be loaded into huggingface\n",
    "# train_df.to_csv(\"data/model_splits/left_right_split/right_as_train/train-00000-of-00001.csv\", index=False)\n",
    "# val_df.to_csv(\"data/model_splits/left_right_split/right_as_train/validation-00000-of-00001.csv\", index=False)\n",
    "# test_df.to_csv(\"data/model_splits/left_right_split/right_as_train/test-00000-of-00001.csv\", index=False)\n",
    "# inference_left_df.to_csv(\"data/model_splits/left_right_split/right_as_train/inference_left-00000-of-00001.csv\", index=False)\n",
    "# inference_center_df.to_csv(\"data/model_splits/left_right_split/right_as_train/inference_center-00000-of-00001.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(manifesto_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RILE proportions in train:\n",
      " RILE\n",
      "0    0.497915\n",
      "2    0.279925\n",
      "1    0.222160\n",
      "Name: count, dtype: float64\n",
      "\n",
      "RILE proportions in validation:\n",
      " RILE\n",
      "0    0.455418\n",
      "2    0.283165\n",
      "1    0.261417\n",
      "Name: count, dtype: float64\n",
      "\n",
      "RILE proportions in test:\n",
      " RILE\n",
      "0    0.516943\n",
      "2    0.245010\n",
      "1    0.238048\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"RILE proportions in train:\\n\", train_df[\"RILE\"].value_counts()/train_df.shape[0])\n",
    "print(\"\\nRILE proportions in validation:\\n\", val_df[\"RILE\"].value_counts()/val_df.shape[0])\n",
    "print(\"\\nRILE proportions in test:\\n\", test_df[\"RILE\"].value_counts()/test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RILE proportions in inference left:\n",
      " RILE\n",
      "0    0.556486\n",
      "1    0.314989\n",
      "2    0.128525\n",
      "Name: count, dtype: float64\n",
      "\n",
      "RILE proportions in inference center:\n",
      " RILE\n",
      "0    0.551593\n",
      "1    0.275137\n",
      "2    0.173270\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nRILE proportions in inference left:\\n\", inference_left_df[\"RILE\"].value_counts()/inference_left_df.shape[0])\n",
    "print(\"\\nRILE proportions in inference center:\\n\", inference_center_df[\"RILE\"].value_counts()/inference_center_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Green Split\n",
    "Creating Training data based on non-green parties (and an inference set with the green parties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "green\n",
       "0    178827\n",
       "1     23264\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df[\"green\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_df = corpus_df[corpus_df[\"green\"] == 1]\n",
    "other_df = corpus_df[corpus_df[\"green\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what columns do we need in the data for the model?\n",
    "relevant_cols = [\"q_sentence\", \"q_sentence_nr\", \"manifesto_id\", \"main_codes\", \"green_code\", \"original_index\"]\n",
    "green_df = green_df[relevant_cols]\n",
    "other_df = other_df[relevant_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of q_sentences in the training set: 16189\n",
      "Number of q_sentences in the validation set: 3578\n",
      "Number of q_sentences in the test set: 3497\n",
      "Percentage of the train set: 0.6958820495185695\n",
      "Percentage of the validation set: 0.15379986244841815\n",
      "Percentage of the test set: 0.1503180880330124\n"
     ]
    }
   ],
   "source": [
    "# green as train\n",
    "# train: 70% Green\n",
    "# validation: 15% Green\n",
    "# test: 15% Green\n",
    "# inference: 100% non-Green\n",
    "\n",
    "# split on manifestos:\n",
    "manifesto_ids = green_df[\"manifesto_id\"].unique()\n",
    "np.random.seed(13) # keep it reproducible (and so that ca. 10% of the q_sentences land in the validation set)\n",
    "np.random.shuffle(manifesto_ids)\n",
    "\n",
    "# select manifestos into the different sets (so that about 15% of q_sentences are in the validation and test sets, see below)\n",
    "train_manifesto_ids = manifesto_ids[10:] # 10 manifestos\n",
    "val_manifesto_ids = manifesto_ids[:3] # this is 3 manifestos\n",
    "test_manifesto_ids = manifesto_ids[3:10] # 7 manifestos\n",
    "\n",
    "train_df = green_df[green_df[\"manifesto_id\"].isin(train_manifesto_ids)]\n",
    "val_df = green_df[green_df[\"manifesto_id\"].isin(val_manifesto_ids)]\n",
    "test_df = green_df[green_df[\"manifesto_id\"].isin(test_manifesto_ids)]\n",
    "inference_df = other_df.copy()\n",
    "\n",
    "print(\"Number of q_sentences in the training set:\", train_df.shape[0])\n",
    "print(\"Number of q_sentences in the validation set:\", val_df.shape[0])\n",
    "print(\"Number of q_sentences in the test set:\", test_df.shape[0])\n",
    "print(\"Percentage of the train set:\", train_df.shape[0]/green_df.shape[0])\n",
    "print(\"Percentage of the validation set:\", val_df.shape[0]/green_df.shape[0])\n",
    "print(\"Percentage of the test set:\", test_df.shape[0]/green_df.shape[0])\n",
    "\n",
    "# make sure they are sorted correctly (important for adding the context later on)\n",
    "train_df = train_df.sort_values([\"manifesto_id\", \"q_sentence_nr\"], ascending=True)\n",
    "val_df = val_df.sort_values([\"manifesto_id\", \"q_sentence_nr\"], ascending=True)\n",
    "test_df = test_df.sort_values([\"manifesto_id\", \"q_sentence_nr\"], ascending=True)\n",
    "inference_df = inference_df.sort_values([\"manifesto_id\", \"q_sentence_nr\"], ascending=True)\n",
    "\n",
    "# and reset the indicies\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "val_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "inference_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# and now save them as csv so that they can be loaded into huggingface\n",
    "# train_df.to_csv(\"data/model_splits/green_split/green_as_train/train-00000-of-00001.csv\", index=False)\n",
    "# val_df.to_csv(\"data/model_splits/green_split/green_as_train/validation-00000-of-00001.csv\", index=False)\n",
    "# test_df.to_csv(\"data/model_splits/green_split/green_as_train/test-00000-of-00001.csv\", index=False)\n",
    "# inference_df.to_csv(\"data/model_splits/green_split/green_as_train/inference-00000-of-00001.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(manifesto_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of green codes in train:  0.14855766261041448\n",
      "Percentage of green codes in validation:  0.1811067635550587\n",
      "Percentage of green codes in test:  0.12896768658850444\n",
      "Percentage of green codes in inference:  0.03909924116604316\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of green codes in train: \", sum(train_df[\"green_code\"])/train_df.shape[0])\n",
    "print(\"Percentage of green codes in validation: \", sum(val_df[\"green_code\"])/val_df.shape[0])\n",
    "print(\"Percentage of green codes in test: \", sum(test_df[\"green_code\"])/test_df.shape[0])\n",
    "print(\"Percentage of green codes in inference: \", sum(inference_df[\"green_code\"])/inference_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of q_sentences in the training set: 123816\n",
      "Number of q_sentences in the validation set: 26220\n",
      "Number of q_sentences in the test set: 28791\n",
      "Percentage of the train set: 0.6923786676508581\n",
      "Percentage of the validation set: 0.14662215437266185\n",
      "Percentage of the test set: 0.16099917797648006\n"
     ]
    }
   ],
   "source": [
    "# non-green as train\n",
    "# train: 70% non-Green\n",
    "# validation: 15% non-Green\n",
    "# test: 15% non-Green\n",
    "# inference: 100% Green\n",
    "\n",
    "# split on manifestos:\n",
    "manifesto_ids = other_df[\"manifesto_id\"].unique()\n",
    "np.random.seed(0) # keep it reproducible (and so that ca. 10% of the q_sentences land in the validation set)\n",
    "np.random.shuffle(manifesto_ids)\n",
    "\n",
    "# select manifestos into the different sets (so that about 15% of q_sentences are in the validation and test sets, see below)\n",
    "train_manifesto_ids = manifesto_ids[56:] # \n",
    "val_manifesto_ids = manifesto_ids[:28] # \n",
    "test_manifesto_ids = manifesto_ids[28:56] # \n",
    "\n",
    "train_df = other_df[other_df[\"manifesto_id\"].isin(train_manifesto_ids)]\n",
    "val_df = other_df[other_df[\"manifesto_id\"].isin(val_manifesto_ids)]\n",
    "test_df = other_df[other_df[\"manifesto_id\"].isin(test_manifesto_ids)]\n",
    "inference_df = green_df.copy()\n",
    "\n",
    "print(\"Number of q_sentences in the training set:\", train_df.shape[0])\n",
    "print(\"Number of q_sentences in the validation set:\", val_df.shape[0])\n",
    "print(\"Number of q_sentences in the test set:\", test_df.shape[0])\n",
    "print(\"Percentage of the train set:\", train_df.shape[0]/other_df.shape[0])\n",
    "print(\"Percentage of the validation set:\", val_df.shape[0]/other_df.shape[0])\n",
    "print(\"Percentage of the test set:\", test_df.shape[0]/other_df.shape[0])\n",
    "\n",
    "# make sure they are sorted correctly (important for adding the context later on)\n",
    "train_df = train_df.sort_values([\"manifesto_id\", \"q_sentence_nr\"], ascending=True)\n",
    "val_df = val_df.sort_values([\"manifesto_id\", \"q_sentence_nr\"], ascending=True)\n",
    "test_df = test_df.sort_values([\"manifesto_id\", \"q_sentence_nr\"], ascending=True)\n",
    "inference_df = inference_df.sort_values([\"manifesto_id\", \"q_sentence_nr\"], ascending=True)\n",
    "\n",
    "# and reset the indicies\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "val_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)\n",
    "inference_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# and now save them as csv so that they can be loaded into huggingface\n",
    "# train_df.to_csv(\"data/model_splits/green_split/non_green_as_train/train-00000-of-00001.csv\", index=False)\n",
    "# val_df.to_csv(\"data/model_splits/green_split/non_green_as_train/validation-00000-of-00001.csv\", index=False)\n",
    "# test_df.to_csv(\"data/model_splits/green_split/non_green_as_train/test-00000-of-00001.csv\", index=False)\n",
    "# inference_df.to_csv(\"data/model_splits/green_split/non_green_as_train/inference-00000-of-00001.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(manifesto_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of green codes in train:  0.03909026297085998\n",
      "Percentage of green codes in validation:  0.037795575896262396\n",
      "Percentage of green codes in test:  0.0403251015942482\n",
      "Percentage of green codes in inference:  0.15061898211829436\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of green codes in train: \", sum(train_df[\"green_code\"])/train_df.shape[0])\n",
    "print(\"Percentage of green codes in validation: \", sum(val_df[\"green_code\"])/val_df.shape[0])\n",
    "print(\"Percentage of green codes in test: \", sum(test_df[\"green_code\"])/test_df.shape[0])\n",
    "print(\"Percentage of green codes in inference: \", sum(inference_df[\"green_code\"])/inference_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
