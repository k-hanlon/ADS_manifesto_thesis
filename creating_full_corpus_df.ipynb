{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook combines the corpus/text data with the more general MPDS data, creating two xlsx files. One with all quasi sentences, one where quasi sentences without a code were removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's load one of the prepared corpus datasets:\n",
    "corpus_df_start = pd.read_excel(\"data/english_annotated_corpus.xlsx\")\n",
    "# mpds contains coderid etc for all documents (with party+date being the key)\n",
    "mpds = pd.read_excel(\"data/MPDS2023a.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets add info from mpds to the corpus df:\n",
    "mpds_subset = mpds[[\"party\", \"date\", \"coderid\", \"countryname\", \"partyname\", \"pervote\"]]\n",
    "corpus_df = corpus_df_start.merge(mpds_subset, on=[\"date\", \"party\"], how=\"left\")\n",
    "\n",
    "# lets also add columns telling us the length of the quasi-sentences\n",
    "corpus_df[\"q_sentence_chars\"] = corpus_df[\"q_sentence\"].apply(len)\n",
    "corpus_df[\"q_sentence_words\"] = corpus_df[\"q_sentence\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# lets also create a column \"main_codes\" where the subcodes are changed back to their main code\n",
    "# to do this, we basically just keep the first three characters of each code\n",
    "def extract_main_code(x):\n",
    "    # if it's not a string, it's NAN, so just return it\n",
    "    return x[0:3] if isinstance(x, str) else x\n",
    "corpus_df[\"main_codes\"] = corpus_df[\"codes\"].apply(extract_main_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace H and NA codes with numer (0 and -1 respectively)\n",
    "corpus_df['main_codes'].replace('H', 0, inplace=True)\n",
    "corpus_df['main_codes'].fillna(-1, inplace=True)\n",
    "\n",
    "# Add RILE categorization:\n",
    "left = [103, 105, 106, 107, 202, 403, 404, 406, 412, 413, 504, 506, 701] #coded as 1\n",
    "right = [104, 201, 203, 305, 401, 402, 407, 414, 505, 601, 603, 605, 606] #coded as 2, neutral as 0\n",
    "corpus_df['RILE'] = corpus_df['main_codes'].apply(lambda x: 1 if int(x) in left else (2 if int(x) in right else 0))\n",
    "\n",
    "# full will still contains everything\n",
    "corpus_df_full = corpus_df.copy()\n",
    "\n",
    "#corpus_df removes H and NA rows:\n",
    "corpus_df = corpus_df[corpus_df['main_codes'] != 0]\n",
    "corpus_df = corpus_df[corpus_df['main_codes'] != -1]\n",
    "\n",
    "# drop the current index, but saved it so we can correspond with the full version\n",
    "corpus_df['full_index'] = corpus_df.index\n",
    "corpus_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframes\n",
    "corpus_df.to_csv(\"data/english_annotated_df.csv\", index=False)\n",
    "corpus_df_full.to_csv(\"data/english_annotated_full_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
